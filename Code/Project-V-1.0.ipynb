{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtubeâ€™s automated speech recognition, captioning and sentiment analysis for non-native English speakers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Duubar Villalobos Jimenez (CUNY SPS Masters in Data Science) &**\n",
    "\n",
    "**Dipika Shrestha (CUNY Baruch College Masters in Public & International Affairs)**\n",
    "\n",
    "New York City, New York.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "08.28.2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New York City is a city full of diversity; our residents come from different countries, and many speak a different language other than English as their primary source of communication.\n",
    "\n",
    "Those who emigrate, find the need of communicating their experiences, struggles, and success to others who like them face similar challenges. A great way of communicating is by recording mostly in English and posting on YouTube for the world to see.\n",
    "\n",
    "With the advancements in Artificial Intelligence, YouTube has added different services to its platform, one of them by providing automated captioning to their videos. And here is where our proposed idea comes in. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our initial question is as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do automated YouTube captioning affect the sentiment of the message given by a  non-native English speaking person?**\n",
    "\n",
    "In order to answer this question, we are seeking two different hypotheses:\n",
    "\n",
    "- **Null hypothesis:** The sentiment does not get affected.\n",
    "\n",
    "- **Alternate hypothesis:** The sentiment gets affected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, moving forward and based on the answer we get, we might then suggest strategic approaches in order to overcome the effect of the sentiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using English as a Lingua Franca and comparing it with YouTube automated captioning; we can then study the communication between non-native English speakers from YouTube videos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our goals could be defined as follows:**\n",
    "    \n",
    "1. What problems are encountered by people who required to communicate in English, when English is not their native language?\n",
    "\n",
    "2. What possible benefits may accrue if a given opportunity is given in order to receive captioned/spoken English messages in their native language?\n",
    "\n",
    "3. To what extent do misunderstandings occur owing to language differences and how could these confusions ultimately be resolved with the captioned message?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer these questions, we will work closely by ensuring that the Scientific Method is followed accordingly; we will employ Induction, as it derives new knowledge by generalizing from particular events or objects. Induction has been refined in science to include observing nature, generating a hypothesis from observations, then testing our hypothesis by experiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to ensure that our experiments will be completed, we will make use of:**\n",
    "\n",
    "- YouTube videos.\n",
    "- YouTube automated captions.\n",
    "- Python and some relevant libraries.\n",
    "- R and some related libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other tools that might be considered along the way depending on various thoughts are:**\n",
    "\n",
    "- Amazon Rekognition.\n",
    "- The IBM Watson Speech to Text service.\n",
    "- Google Cloud Speech-to-Text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUNY High-Performance Computing Center**\n",
    "\n",
    "We might need to make use of the CUNY High-Performance Computing Center, for which we need to make acknowledgment as follows:\n",
    "\n",
    "*The CUNY HPCC is operated by the College of Staten Island and funded, in part, by grants from the City of New York, State of New York, CUNY Research Foundation, and National Science Foundation Grants CNS-0958379, CNS-0855217 and ACI 1126113.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Building\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we are in the initial ideas and proposals.\n",
    "Our team got approvals from both of our advisors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Proposal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This to be our proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract automated transcript from YouTube video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script, is a Python generated code in which we will use in order to extract the automatic generated transcript from youtube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Python API which allows you to get the transcripts/subtitles for  a given YouTube video. It also works for automatically generated subtitles and it does not require a headless browser, like other selenium based solutions do!\n",
    "\n",
    "For further learning, visit [https://pypi.org/project/youtube-transcript-api/](https://pypi.org/project/youtube-transcript-api/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To supress warning messages\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# get data directory (using getcwd() is needed to support running example in generated IPython notebook)\n",
    "d = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/youtube-transcript-api/\n",
    "# pip3 install youtube_transcript_api\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import json\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the StopWords\n",
    "STOPWORDS = set(STOPWORDS)\n",
    "STOPWORDS.add(\"yeah\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have captured the automated transcription generated by YouTube. We then, will compare the original transcript to the automated generated transcript and perform a small introductory analysis in order to gather some initial insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract transcript from the video directly from Youtube\n",
    "# The transcript will return a list with the following column indicators\n",
    "# \"duration\", \"start\", \"text\"\n",
    "\n",
    "# Function that extract the YouTube automated transcript\n",
    "def getYouTubeTranscript(YouTubeID):\n",
    "\n",
    "    # Extract transcript by following https://pypi.org/project/youtube-transcript-api/\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(YouTubeID)\n",
    "\n",
    "    # Convert from Json list into Pandas Data frame\n",
    "    df_YouTube = pd.DataFrame(transcript)\n",
    "\n",
    "    # Rename columns\n",
    "    df_YouTube.columns = ['Duration','Start','Automated']\n",
    "\n",
    "    # Return transcript\n",
    "    return(df_YouTube);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract an example from YouTube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get single YouTube automated transcript\n",
    "# The link for our first video to test our hypothesis is as follows: \n",
    "# https://www.youtube.com/watch?v=a16z2mE_69s\n",
    "df_YouTube = getYouTubeTranscript('uXJwQNEXuug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the orginal transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import previously manually cleaned transcribed video.\n",
    "df_Transcript = pd.read_csv( d + \"/data/Transcripts/a16z2mE_69s-CorrectTranscript.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add correct transcript column next to YouTube automated transcript column\n",
    "def compareTranscripts(df_YouTube, df_Transcript):\n",
    "    \n",
    "    # Joining columns in a single data frame\n",
    "    df_YouTube['Original'] = df_Transcript['text']\n",
    "\n",
    "    # Finding out if there's a difference in the text\n",
    "    df_YouTube['Different'] = np.where((df_YouTube['Automated'] == df_YouTube['Original']), 'No', 'Yes')\n",
    "\n",
    "    # Comparing the first 5 records.\n",
    "    #df_YouTube.head()\n",
    "    return(df_YouTube);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a small visualization\n",
    "df = compareTranscripts(df_YouTube, df_Transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the duration frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(9, 9), sharey=True)\n",
    "\n",
    "# We can set the number of bins with the `bins` kwarg\n",
    "axs.hist(df['Duration'], bins=100)\n",
    "axs.set_xlabel('Duration in seconds')\n",
    "axs.set_ylabel('Counts in units')\n",
    "fig.suptitle('Sentence time duration distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize the differences observed in the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Different'].value_counts().plot(kind='bar',\n",
    "                                    title='Transcripts and differences',\n",
    "                                    figsize=(9, 9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we can now start wondering if the question we have formulated, could help us understand if the automated YouTube transcript has any effect in the sentiment of the message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following procedure will extract a wordcloud from the captionings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to extract valuable information, we need to make sure our text is converted to string\n",
    "df['Automated'] = df['Automated'].astype(str)\n",
    "df['Original'] = df['Original'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to extract the core of the message, all the stop words will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of STOPWORDS\n",
    "df_StopWords = pd.DataFrame(STOPWORDS).head(10)\n",
    "df_StopWords.columns = ['STOPWORDS']\n",
    "df_StopWords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that extract the WordCloud from a Pandas data frame column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning Wordcloud captioning fom Pandas Data frame column\n",
    "def getWordCloud(df, Column):\n",
    "\n",
    "    ## Join all sentences in the Automated YouTube corpus\n",
    "    text = ' '.join(df[Column])\n",
    "\n",
    "    wc = WordCloud(width = 800,\n",
    "                   height = 800, \n",
    "                   background_color ='black',\n",
    "                   stopwords = STOPWORDS,\n",
    "                   min_font_size = 10)\n",
    "    \n",
    "    wc = wc.generate(text)\n",
    "    \n",
    "    return(wc);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that plot an already extracted WordCloud from a Pandas data frame column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure to plot wordcloud from based on a column\n",
    "def WordCloudImage(Cloud):\n",
    "    \n",
    "    # read the mask image\n",
    "    # taken from\n",
    "    # https://www.cleanpng.com/png-immigration-israel-computer-icons-aliyah-family-to-2502696/download-png.html\n",
    "    \n",
    "    fig = plt.figure(\n",
    "        figsize = (40, 30),\n",
    "        facecolor = 'k',\n",
    "        edgecolor = 'k')    \n",
    "    plt.imshow(Cloud, \n",
    "               interpolation = 'bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "    \n",
    "    return;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the respective WordClouds for the Automated YouTube captioning and the Original captioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract WordCloud from YouTube's automatic transcript\n",
    "wordcloud_YouTube = getWordCloud(df, 'Automated')\n",
    "# Extract WordCloud from Original Transcript\n",
    "wordcloud_Original = getWordCloud(df, 'Original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube Automated captioning WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return WordCloud for YouTube automated Captioning\n",
    "WordCloudImage(wordcloud_YouTube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original captioninig WordCloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return WordCloud for Original Transcription\n",
    "WordCloudImage(wordcloud_Original)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
